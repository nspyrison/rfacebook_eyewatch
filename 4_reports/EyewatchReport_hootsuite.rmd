---
title: "Eyewatch facebook posts -- via Hootsuite"
author: "Nicholas Spyrison"
date: "Jan 2019"
output: 
  html_document:
    self_contained: true
---
```{r options, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  collapse = TRUE,
  comment = "",
  fig.height = 8,
  fig.width = 12,
  fig.align = "center",
  cache = FALSE)

library("readr")
library("dplyr")
library("tibble")
library("tsibble")
library("ggplot2")
library("lubridate")
library("plotly")

load("../3_staged_data/bound_data_2019-01-23.rda")
dat <- bound_data
```

A cleaned, filtered data set of `r round(nrow(dat))` facebook posts accross `r round(ncol(dat))` variables for all 55 police stations pages was exported from Hootsuite. The data ranges from `r round(min(dat$Date))` through `r round(max(dat$Date))`. Posts before 18 November 2017 are not available on the Hootsuite platform. The below graphs were made from made from this data.

```{r, eval=T,include=F}
sub <- dat[c("Station", "YearMonth", "Reactions", "Comments",
                  "Shares", "Engagements")]
agg <- summarize(.data = sub,
                 CountStaions     = length(unique(Station)),
                 CountYearMonths  = length(unique(YearMonth)),
                 MeanPostsPm      = n()/length(unique(YearMonth)),
                 MeanReactionsPp  = mean(Reactions),
                 MeanSharesPp     = mean(Shares),
                 MeanCommentsPp   = mean(Comments),
                 MeanEngagementPp = mean(Engagements)
)
```

## Posts by time

```{r, echo=F}
(g1 <-
  ggplot(data = dat, aes(x = `Date`, fill = PostType) ) +
  geom_histogram(bins = length(unique(dat$YearWeek))) +
  ggtitle("Post vs time (by post type)") +
  ylab("Number of Posts") + xlab("Time (each bar is 1 week)") +
  scale_fill_brewer(palette = "Dark2") 
)
```

## Engagement by month across post type

```{r, echo=F}
agg1 <-
  dat %>%
  group_by(YearMonth) %>%
  summarise (Engagements = sum(Engagements),
             Posts = n(),
             Engagements_pp = sum(Engagements)/n())

(g2 <- ggplot(data = dat, aes(x = YearWeek)) +
   geom_bar(aes(y = Engagements/1000, fill = PostType), stat = 'identity') + 
   ggtitle("Engagements vs time (by post type)") +
   xlab("Time (each bar is 1 week)") + ylab("1,000x Engagments") +
   scale_fill_brewer(palette = "Dark2")
)

ggplot(data = agg1) +
  geom_line(aes(x=YearMonth, y= Posts/max(Posts), color = "Rate of posts")) +
  geom_line(aes(x=YearMonth, y= Engagements_pp/max(Engagements_pp), color = "Rate of Engagements"))
  # + scale_y_continuous(sec.axis = sec_axis(~., name = "Engagements per Post"))


```

The bulk of engagements are with photo posts.

## Mean engagements trends by time across post type

Do we see engagement across post type changing over time?

```{r, include=F}
# (g2 <- ggplot(dat, 
#               aes(x = `Date`, y = Engagements, fill = PostType ) ) +
#    geom_smooth() + scale_fill_brewer(palette = "Dark2") + xlab("Time") + 
#    coord_cartesian(ylim = c(0, 100)) 
# )
```

## Engagement by post type across post age

Of the bottom 95% of posts by engagement.

```{r, echo=F}
p3 <- ggplot(data = dat, 
             aes(x = PostType, y = Engagements, 
                 color = -DaysOld, id = PagePostID)) + 
  geom_point(alpha = .4, position = "jitter") + 
  scale_y_continuous(limits = c(0, quantile(dat$Engagements, .95)) ) 
plotly::ggplotly(p3)
```

## High engagment posts: engagement by post type across post age 

Taking a closer look at high engagement posts. Looking at the same graph for only the top 10% of engaged posts.

```{r, echo=F}
p4 <- ggplot(data = dat, 
             aes(x = PostType, y = Engagements, 
                 color = -DaysOld, id = PagePostID)) + 
  geom_point(alpha = .6, position = "jitter") + 
  scale_y_continuous(limits = 
                       c(quantile(dat$Engagements, .90),
                         max(dat$Engagements)*1.01 ) 
  ) + scale_fill_brewer(palette = "Dark2")
plotly::ggplotly(p4)
```

### Appendix

All times are listed in GMT. `story` is NA if there is no message with a post, other than that the data has low missingness.

```{r, echo=F}
sub <- dat[c("YearMonth", "Reactions_Anger", "Reactions_Haha",
                   "Reactions_Like","Reactions_Love", "Reactions_Sorry",
                   "Reactions_Wow", "Reactions", "Comments","Shares", 
                   "Engagements")]
sub_samp <- sample_n(sub, 1000)
(a2 <- GGally::ggpairs(data = sub_samp))
```


```{r, echo=F}
a3sub <- 
  dat[c("Station", "Date","Weekday", "DaysOld", "PostType",
             "Reactions_Anger", "Reactions_Haha", "Reactions_Like",
             "Reactions_Love", "Reactions_Sorry", "Reactions_Wow", "Reactions",
             "Comments","Shares", "Engagements")]
summary(a3sub)
```